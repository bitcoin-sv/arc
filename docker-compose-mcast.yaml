version: '3'
services:
  node1:
    container_name: node1
    image: bitcoinsv/bitcoin-sv:1.1.0
    ports:
      - "18332:18332"
    expose:
      - "18332"
      - "18333"
      - "28332"
    healthcheck:
      test: [ "CMD", "/entrypoint.sh", "bitcoin-cli", "getinfo" ]
    volumes:
      - ./test/config/bitcoin.conf:/data/bitcoin.conf
      - node1-data:/data
    command: [ "/entrypoint.sh", "bitcoind", "-connect=node2:18333", "-connect=node3:18333" ]
    networks: 
      - multicast_bridge

  node2:
    container_name: node2
    image: bitcoinsv/bitcoin-sv:1.1.0
    expose:
      - "18332"
      - "18333"
    healthcheck:
      test: [ "CMD", "/entrypoint.sh", "bitcoin-cli", "getinfo" ]
    volumes:
      - ./test/config/bitcoin.conf:/data/bitcoin.conf
      - node2-data:/data
    command: [ "/entrypoint.sh", "bitcoind", "-connect=node1:18333", "-connect=node3:18333" ]
    networks: 
      - multicast_bridge

  node3:
    container_name: node3
    image: bitcoinsv/bitcoin-sv:1.1.0
    expose:
      - "18332"
      - "18333"
    healthcheck:
      test: [ "CMD", "/entrypoint.sh", "bitcoin-cli", "getinfo" ]
    volumes:
      - ./test/config/bitcoin.conf:/data/bitcoin.conf
      - node3-data:/data
    command: [ "/entrypoint.sh", "bitcoind", "-connect=node1:18333", "-connect=node2:18333" ]
    networks:
      - multicast_bridge

  db:
    image: postgres:15.4
    restart: always
    environment:
      - POSTGRES_USER=arcuser
      - POSTGRES_PASSWORD=arcpass
      - POSTGRES_DB=main
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready", "-d blocktx", "-U arcuser" ]
      interval: 5s
      timeout: 5s
      retries: 5
    ports:
      - '5432:5432'
    expose:
      - "5432"
    networks:
      - multicast_bridge
 
  migrate-blocktx:
    container_name: migrate-blocktx
    image: migrate/migrate:v4.16.2
    entrypoint:
      [
        "migrate",
        "-path",
        "/migrations",
        "-database",
        "postgres://arcuser:arcpass@db:5432/main?sslmode=disable&x-migrations-table=blocktx",
      ]
    command: [ "up" ]
    volumes:
      - ./internal/blocktx/store/postgresql/migrations:/migrations
    depends_on:
      db:
        condition: service_healthy
    restart: on-failure
    networks:
      - multicast_bridge

  migrate-metamorph:
    container_name: migrate-metamorph
    image: migrate/migrate:v4.16.2
    entrypoint:
      [
        "migrate",
        "-path",
        "/migrations",
        "-database",
        "postgres://arcuser:arcpass@db:5432/main?sslmode=disable&x-migrations-table=metamorph",
      ]
    command: [ "up" ]
    volumes:
      - ./internal/metamorph/store/postgresql/migrations:/migrations
    depends_on:
      db:
        condition: service_healthy
    restart: on-failure
    networks:
      - multicast_bridge

  migrate-callbacker:
    container_name: migrate-callbacker
    image: migrate/migrate:v4.16.2
    entrypoint:
      [
        "migrate",
        "-path",
        "/migrations",
        "-database",
        "postgres://arcuser:arcpass@db:5432/main?sslmode=disable&x-migrations-table=callbacker",
      ]
    command: [ "up" ]
    volumes:
      - ./internal/callbacker/store/postgresql/migrations:/migrations
    depends_on:
      db:
        condition: service_healthy
    restart: on-failure
    networks:
      - multicast_bridge

  nats-1:
    image: nats:2.10.18-alpine3.20
    container_name: nats-server-1
    restart: on-failure
    ports:
      - "4222:4222"
    hostname: nats-server
    volumes:
      - nats1-data:/data
      - ./test/config/nats-server-host-1.conf:/etc/nats/nats-server.conf
    healthcheck:
      test: wget http://localhost:8222/healthz -q -S -O -
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - multicast_bridge

  nats-2:
    image: nats:2.10.18-alpine3.20
    container_name: nats-server-2
    restart: on-failure
    ports:
      - "4223:4222"
    hostname: nats-server
    volumes:
      - nats2-data:/data
      - ./test/config/nats-server-host-2.conf:/etc/nats/nats-server.conf
    healthcheck:
      test: wget http://localhost:8222/healthz -q -S -O -
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - multicast_bridge

  cache:
    image: redis
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
    networks:
      - multicast_bridge

  mcast_sidecar:
    build:
      context: ./
      dockerfile: ./cmd/mcast/node_sidecar/Dockerfile    
    volumes:
      - ./test/config/config_mcast.yaml:/service/config.yaml
    command: [ "./sidecar", "-config=." ]
    depends_on:
      node1:
        condition: service_healthy
      node2:
        condition: service_healthy
      node3:
        condition: service_healthy
    networks:
      - multicast_bridge

  blocktx:
    build: ./
    expose:
      - "8011"
    volumes:
      - ./test/config/config_mcast.yaml:/service/config.yaml
    command: [ "./arc", "-blocktx=true", "-config=." ]
    environment:
      - ARC_TRACING_ENABLED
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      node1:
        condition: service_healthy
      node2:
        condition: service_healthy
      node3:
        condition: service_healthy
      migrate-blocktx:
        condition: service_completed_successfully
      
    healthcheck:
      test: ["CMD", "/bin/grpc_health_probe", "-addr=:8006", "-service=liveness", "-rpc-timeout=5s"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - multicast_bridge

  callbacker:
    build: ./
    expose:
      - "8021"
    command: [ "./arc", "-callbacker=true", "-config=." ]
    environment:
      - ARC_TRACING_ENABLED
    volumes:
      - ./test/config/config_mcast.yaml:/service/config.yaml
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      migrate-callbacker:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "/bin/grpc_health_probe", "-addr=:8022", "-service=liveness", "-rpc-timeout=5s"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - multicast_bridge

  metamorph:
    build: ./
    expose:
      - "8001"
    command: [ "./arc", "-metamorph=true", "-config=." ]
    environment:
      - ARC_TRACING_ENABLED
    volumes:
      - ./test/config/config_mcast.yaml:/service/config.yaml
    depends_on:
      blocktx:
        condition: service_healthy
      callbacker:
        condition: service_healthy
      cache:
        condition: service_healthy
      migrate-metamorph:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "/bin/grpc_health_probe", "-addr=:8005", "-service=liveness", "-rpc-timeout=5s"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - multicast_bridge

  api:
    build: ./
    ports:
      - "8011:8011"
      - "9090:9090"
      - "9999:9999"
      - "2112:2112"
    expose:
      - "9090"
      - "2112"
    command: [ "./arc", "-api=true", "-config=." ]
    environment:
      - ARC_TRACING_ENABLED
    volumes:
      - ./test/config/config.yaml:/service/config.yaml
    depends_on:
      metamorph:
        condition: service_healthy
    networks:
      - multicast_bridge

  tests:
    build:
      context: ./
      dockerfile: ./test/Dockerfile
    environment:
      - TEST_LOCAL_MCAST=TRUE
    depends_on:
      - api
    networks:
      - multicast_bridge

volumes:
  node1-data:
    external: false
  node2-data:
    external: false
  node3-data:
    external: false
  nats1-data:
    external: false
  nats2-data:
    external: false
  redis-data:
    external: false

networks:
  multicast_bridge:
    driver: bridge
    enable_ipv6: true
    ipam:
      driver: default
      config:
        - subnet: "2001:db8:9::/64"
          gateway: "2001:db8:9::1"
